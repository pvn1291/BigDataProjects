{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit, monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession\\\n",
    "                .builder\\\n",
    "                .master(\"local\")\\\n",
    "                .appName(\"Titanic Classification\")\\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark_session.read.csv(path = 'train.csv', header = True, inferSchema = True)\n",
    "test = spark_session.read.csv(path = 'test.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cabin column has 77% NA values. Drop <br>\n",
    "Age column has 20% NA values. Try to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: 0 0.0\n",
      "Survived: 0 0.0\n",
      "Pclass: 0 0.0\n",
      "Name: 0 0.0\n",
      "Sex: 0 0.0\n",
      "Age: 177 19.87\n",
      "SibSp: 0 0.0\n",
      "Parch: 0 0.0\n",
      "Ticket: 0 0.0\n",
      "Fare: 0 0.0\n",
      "Cabin: 687 77.1\n",
      "Embarked: 2 0.22\n"
     ]
    }
   ],
   "source": [
    "for name in train.schema.names:\n",
    "    na_count = train.filter(train[name].isNull()).count()\n",
    "    na_perc = round(100 * na_count / train.count(), 2)\n",
    "    print(name + \": \" + str(na_count) + \" \" + str(na_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Cabin')\n",
    "test = test.drop('Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset = ['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|Initial|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|     Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|    Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|   Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|    Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|     Mr|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = train.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| Initial|count|\n",
      "+--------+-----+\n",
      "|     Don|    1|\n",
      "|    Miss|  181|\n",
      "|Countess|    1|\n",
      "|     Col|    2|\n",
      "|     Rev|    6|\n",
      "|    Lady|    1|\n",
      "|  Master|   40|\n",
      "|     Mme|    1|\n",
      "|    Capt|    1|\n",
      "|      Mr|  517|\n",
      "|      Dr|    7|\n",
      "|     Mrs|  124|\n",
      "|     Sir|    1|\n",
      "|Jonkheer|    1|\n",
      "|    Mlle|    2|\n",
      "|   Major|    2|\n",
      "|      Ms|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_initial = train.groupBy('Initial').count()\n",
    "grpby_initial.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Uncertainity about initials. So,\n",
    "<b> Imputing missing values using average age of male & female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. female age: 28.0 & Avg. male age: 31.0\n"
     ]
    }
   ],
   "source": [
    "grpby_sex = train.groupBy('Sex')\n",
    "avg_age_vals = grpby_sex.avg('Age').collect()\n",
    "avg_age_vals\n",
    "mean_female_age = round(avg_age_vals[0][1], 0)\n",
    "mean_male_age = round(avg_age_vals[1][1], 0)\n",
    "print(\"Avg. female age: {favg} & Avg. male age: {mavg}\".format(favg = mean_female_age, mavg = mean_male_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('Age', when(condition = (train['Age'].isNull()) & (train['Sex'] == 'male'),\n",
    "                                     value = mean_male_age).otherwise(train['Age']))\n",
    "train = train.withColumn('Age', when(condition = (train['Age'].isNull()) & (train['Sex'] == 'female'),\n",
    "                                     value = mean_female_age).otherwise(train['Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: 0 0.0\n",
      "Survived: 0 0.0\n",
      "Pclass: 0 0.0\n",
      "Name: 0 0.0\n",
      "Sex: 0 0.0\n",
      "Age: 0 0.0\n",
      "SibSp: 0 0.0\n",
      "Parch: 0 0.0\n",
      "Ticket: 0 0.0\n",
      "Fare: 0 0.0\n",
      "Embarked: 0 0.0\n"
     ]
    }
   ],
   "source": [
    "for name in train.schema.names:\n",
    "    na_count = train.filter(train[name].isNull()).count()\n",
    "    na_perc = round(100 * na_count / train.count(), 2)\n",
    "    print(name + \": \" + str(na_count) + \" \" + str(na_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Exploratory Data Analysis </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  214|\n",
      "|     3|  491|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_pclass = train.groupBy('Pclass')\n",
    "grpby_pclass.count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  312|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_sex = train.groupBy('Sex')\n",
    "grpby_sex.count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   Sex|          avg(Age)|\n",
      "+------+------------------+\n",
      "|female| 27.78846153846154|\n",
      "|  male|30.785389948006937|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_sex.avg('Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Observations: </b><br>\n",
    "    <i> Average age of passeners in First class in higher than passengers in second & third class </i><br><br>\n",
    "<b> Insights: </b>   \n",
    "    <i> There might be a relationship between worth of a passenger and its age.<br>\n",
    "    We may say that it took more time to accumulate wealth or to complete education in those days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|          avg(Age)|\n",
      "+------+------------------+\n",
      "|     1|36.983271028037386|\n",
      "|     3|26.506965376782077|\n",
      "|     2| 29.91211956521739|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_pclass.avg('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.19351635514012|\n",
      "|     3|13.675550101832997|\n",
      "|     2| 20.66218315217391|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_pclass.avg('Fare').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_embarked = train.groupBy('Embarked')\n",
    "grpby_embarked.count().show()\n",
    "# Q: Queenstown\n",
    "# C: Cherbourg\n",
    "# S: Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|   Sex|sum(Parch)|\n",
      "+------+----------+\n",
      "|female|       204|\n",
      "|  male|       136|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_sex.sum('Parch').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Passengers in third class were travelling with families. Since higher number of parent/child and siblings/spouse on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Pclass|sum(Parch)|\n",
      "+------+----------+\n",
      "|     1|        77|\n",
      "|     3|       193|\n",
      "|     2|        70|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_pclass.sum('Parch').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Pclass|sum(SibSp)|\n",
      "+------+----------+\n",
      "|     1|        90|\n",
      "|     3|       302|\n",
      "|     2|        74|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_pclass.sum('SibSp').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q: Queenstown C: Cherbourg S: Southampton <br>\n",
    "Observations: <br> </b>\n",
    "<i>Port C: First Class & Second Class <br>\n",
    "Port Q: Predominantly in third class <br>\n",
    "Port S: All of the classes but majority in third class </i><br><br>\n",
    "<b>Insights: <br></b>\n",
    "<i>Port Q: Rural area or under developed region <br>\n",
    "Port S: City or developed region <br>\n",
    "Port c: City or developed region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|Embarked|Pclass|count|\n",
      "+--------+------+-----+\n",
      "|       C|     1|   85|\n",
      "|       C|     2|   17|\n",
      "|       C|     3|   66|\n",
      "|       Q|     1|    2|\n",
      "|       Q|     2|    3|\n",
      "|       Q|     3|   72|\n",
      "|       S|     1|  127|\n",
      "|       S|     2|  164|\n",
      "|       S|     3|  353|\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_embarked_pclass = train.groupBy(['Embarked', 'Pclass'])\n",
    "grpby_embarked_pclass.count().sort(['Embarked', 'Pclass']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|Embarked|   Sex|count|\n",
      "+--------+------+-----+\n",
      "|       C|female|   73|\n",
      "|       C|  male|   95|\n",
      "|       Q|female|   36|\n",
      "|       Q|  male|   41|\n",
      "|       S|female|  203|\n",
      "|       S|  male|  441|\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_embarked_sex = train.groupBy(['Embarked', 'Sex'])\n",
    "grpby_embarked_sex.count().sort(['Embarked', 'Sex']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|31.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|31.0|    0|    0|          244373|   13.0|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|28.0|    0|    0|            2649|  7.225|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preparing dataset for model learning </h3><br>\n",
    "<i> \n",
    "    * Feature Engineering - Combine parent-child and Siblings-spouse columns <br>\n",
    "    * Feature Engineering - Indexers to convert binary categorical columns to numeric indexes <br>\n",
    "    * (Train, Test) = (70, 30)\n",
    "</i><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('Family_Size', col('Parch') + col('SibSp'))\n",
    "test = test.withColumn('Family_Size', col('Parch') + col('SibSp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "    Convert family size to bianry categorical variable, <br>\n",
    "</b> <br>    \n",
    "<i>\n",
    "    * 0 for passenger travelling alone <br>\n",
    "    * 1 for passenger travelling with family\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('Family_Flag', when(condition = (train['Family_Size'] == 0), value = (0)).otherwise(1))\n",
    "test = test.withColumn('Family_Flag', when(condition = (test['Family_Size'] == 0), value = (0)).otherwise(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Indexers for categorical columns </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = [StringIndexer(inputCol = cat_feature, outputCol = cat_feature + '_dummy').fit(train) for cat_feature in ['Sex', 'Embarked']]\n",
    "indexer_test = [StringIndexer(inputCol = cat_feature, outputCol = cat_feature + '_dummy').fit(test) for cat_feature in ['Sex', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Pipeline(stages = indexer).fit(train).transform(train)\n",
    "test = Pipeline(stages = indexer_test).fit(test).transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---------+------+\n",
      "|Embarked|Embarked_dummy|Sex_dummy|   Sex|\n",
      "+--------+--------------+---------+------+\n",
      "|       S|           0.0|      0.0|  male|\n",
      "|       C|           1.0|      1.0|female|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       S|           0.0|      0.0|  male|\n",
      "|       Q|           2.0|      0.0|  male|\n",
      "|       S|           0.0|      0.0|  male|\n",
      "|       S|           0.0|      0.0|  male|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       C|           1.0|      1.0|female|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       S|           0.0|      0.0|  male|\n",
      "|       S|           0.0|      0.0|  male|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       Q|           2.0|      0.0|  male|\n",
      "|       S|           0.0|      0.0|  male|\n",
      "|       S|           0.0|      1.0|female|\n",
      "|       C|           1.0|      1.0|female|\n",
      "+--------+--------------+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select(['Embarked', 'Embarked_dummy', 'Sex_dummy', 'Sex']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Indexer Output </b> <br>\n",
    "<b> Indexer assign 0.0 to most frequent label in the feature </b> <br>\n",
    "<i>\n",
    "    * for sex = {male - 577, female - 312}, male = 0.0, female = 1.0\n",
    "    * for embarked = {S - 644, Q - 77, C - 168}, S = 0.0, C = 1.0, Q = 2.0\n",
    "</i>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked', 'Family_Size', 'Family_Flag', 'Sex_dummy', 'Embarked_dummy']\n"
     ]
    }
   ],
   "source": [
    "print('Features = {}'.format(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: 0 0.0\n",
      "Survived: 0 0.0\n",
      "Pclass: 0 0.0\n",
      "Name: 0 0.0\n",
      "Sex: 0 0.0\n",
      "Age: 0 0.0\n",
      "SibSp: 0 0.0\n",
      "Parch: 0 0.0\n",
      "Ticket: 0 0.0\n",
      "Fare: 0 0.0\n",
      "Embarked: 0 0.0\n",
      "Family_Size: 0 0.0\n",
      "Family_Flag: 0 0.0\n",
      "Sex_dummy: 0 0.0\n",
      "Embarked_dummy: 0 0.0\n"
     ]
    }
   ],
   "source": [
    "for name in train.schema.names:\n",
    "    na_count = train.filter(train[name].isNull()).count()\n",
    "    na_perc = round(100 * na_count / train.count(), 2)\n",
    "    print(name + \": \" + str(na_count) + \" \" + str(na_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Drop labels </b> <br>\n",
    "<i>\n",
    "    * PassengerId\n",
    "    * Name\n",
    "    * Sex\n",
    "    * SibSp\n",
    "    * Parch\n",
    "    * Ticket\n",
    "    * Cabin\n",
    "    * Embarked\n",
    "    * Family_Size\n",
    "</i>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Survived', 'PClass', 'Age', 'Fare', 'Embarked_dummy', 'Sex_dummy', 'Family_Flag']\n",
    "new_train = train.select(features)\n",
    "new_test = test.select(features[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- PClass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked_dummy: double (nullable = false)\n",
      " |-- Sex_dummy: double (nullable = false)\n",
      " |-- Family_Flag: integer (nullable = false)\n",
      "\n",
      "+--------+------+----+-------+--------------+---------+-----------+\n",
      "|Survived|PClass| Age|   Fare|Embarked_dummy|Sex_dummy|Family_Flag|\n",
      "+--------+------+----+-------+--------------+---------+-----------+\n",
      "|       0|     3|22.0|   7.25|           0.0|      0.0|          1|\n",
      "|       1|     1|38.0|71.2833|           1.0|      1.0|          1|\n",
      "|       1|     3|26.0|  7.925|           0.0|      1.0|          0|\n",
      "|       1|     1|35.0|   53.1|           0.0|      1.0|          1|\n",
      "|       0|     3|35.0|   8.05|           0.0|      0.0|          0|\n",
      "|       0|     3|31.0| 8.4583|           2.0|      0.0|          0|\n",
      "|       0|     1|54.0|51.8625|           0.0|      0.0|          0|\n",
      "|       0|     3| 2.0| 21.075|           0.0|      0.0|          1|\n",
      "|       1|     3|27.0|11.1333|           0.0|      1.0|          1|\n",
      "|       1|     2|14.0|30.0708|           1.0|      1.0|          1|\n",
      "|       1|     3| 4.0|   16.7|           0.0|      1.0|          1|\n",
      "|       1|     1|58.0|  26.55|           0.0|      1.0|          0|\n",
      "|       0|     3|20.0|   8.05|           0.0|      0.0|          0|\n",
      "|       0|     3|39.0| 31.275|           0.0|      0.0|          1|\n",
      "|       0|     3|14.0| 7.8542|           0.0|      1.0|          0|\n",
      "|       1|     2|55.0|   16.0|           0.0|      1.0|          0|\n",
      "|       0|     3| 2.0| 29.125|           2.0|      0.0|          1|\n",
      "|       1|     2|31.0|   13.0|           0.0|      0.0|          0|\n",
      "|       0|     3|31.0|   18.0|           0.0|      1.0|          1|\n",
      "|       1|     3|28.0|  7.225|           1.0|      1.0|          0|\n",
      "+--------+------+----+-------+--------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Survived: 0 0.0\n",
      "PClass: 0 0.0\n",
      "Age: 0 0.0\n",
      "Fare: 0 0.0\n",
      "Embarked_dummy: 0 0.0\n",
      "Sex_dummy: 0 0.0\n",
      "Family_Flag: 0 0.0\n"
     ]
    }
   ],
   "source": [
    "new_train.printSchema()\n",
    "new_train.show()\n",
    "\n",
    "for name in new_train.schema.names:\n",
    "    na_count = new_train.filter(train[name].isNull()).count()\n",
    "    na_perc = round(100 * na_count / new_train.count(), 2)\n",
    "    print(name + \": \" + str(na_count) + \" \" + str(na_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train test split, 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler(inputCols = new_train.columns[1:], outputCol = 'feat_vector')\n",
    "dataset = vector_assembler.transform(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- PClass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked_dummy: double (nullable = false)\n",
      " |-- Sex_dummy: double (nullable = false)\n",
      " |-- Family_Flag: integer (nullable = false)\n",
      " |-- feat_vector: vector (nullable = true)\n",
      "\n",
      "+--------+------+----+-------+--------------+---------+-----------+--------------------+\n",
      "|Survived|PClass| Age|   Fare|Embarked_dummy|Sex_dummy|Family_Flag|         feat_vector|\n",
      "+--------+------+----+-------+--------------+---------+-----------+--------------------+\n",
      "|       0|     3|22.0|   7.25|           0.0|      0.0|          1|[3.0,22.0,7.25,0....|\n",
      "|       1|     1|38.0|71.2833|           1.0|      1.0|          1|[1.0,38.0,71.2833...|\n",
      "|       1|     3|26.0|  7.925|           0.0|      1.0|          0|[3.0,26.0,7.925,0...|\n",
      "|       1|     1|35.0|   53.1|           0.0|      1.0|          1|[1.0,35.0,53.1,0....|\n",
      "|       0|     3|35.0|   8.05|           0.0|      0.0|          0|[3.0,35.0,8.05,0....|\n",
      "|       0|     3|31.0| 8.4583|           2.0|      0.0|          0|[3.0,31.0,8.4583,...|\n",
      "|       0|     1|54.0|51.8625|           0.0|      0.0|          0|[1.0,54.0,51.8625...|\n",
      "|       0|     3| 2.0| 21.075|           0.0|      0.0|          1|[3.0,2.0,21.075,0...|\n",
      "|       1|     3|27.0|11.1333|           0.0|      1.0|          1|[3.0,27.0,11.1333...|\n",
      "|       1|     2|14.0|30.0708|           1.0|      1.0|          1|[2.0,14.0,30.0708...|\n",
      "|       1|     3| 4.0|   16.7|           0.0|      1.0|          1|[3.0,4.0,16.7,0.0...|\n",
      "|       1|     1|58.0|  26.55|           0.0|      1.0|          0|[1.0,58.0,26.55,0...|\n",
      "|       0|     3|20.0|   8.05|           0.0|      0.0|          0|[3.0,20.0,8.05,0....|\n",
      "|       0|     3|39.0| 31.275|           0.0|      0.0|          1|[3.0,39.0,31.275,...|\n",
      "|       0|     3|14.0| 7.8542|           0.0|      1.0|          0|[3.0,14.0,7.8542,...|\n",
      "|       1|     2|55.0|   16.0|           0.0|      1.0|          0|[2.0,55.0,16.0,0....|\n",
      "|       0|     3| 2.0| 29.125|           2.0|      0.0|          1|[3.0,2.0,29.125,2...|\n",
      "|       1|     2|31.0|   13.0|           0.0|      0.0|          0|[2.0,31.0,13.0,0....|\n",
      "|       0|     3|31.0|   18.0|           0.0|      1.0|          1|[3.0,31.0,18.0,0....|\n",
      "|       1|     3|28.0|  7.225|           1.0|      1.0|          0|[3.0,28.0,7.225,1...|\n",
      "+--------+------+----+-------+--------------+---------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- feat_vector: vector (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_dataset = dataset.select('feat_vector', 'Survived')\n",
    "final_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainSet, testSet) = final_dataset.randomSplit(weights = [0.7, 0.3], seed = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- feat_vector: vector (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- feat_vector: vector (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSet.printSchema()\n",
    "testSet.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Models</h2> <br>\n",
    "<i><b> Process: </b>\n",
    "    <ol>\n",
    "        <li>Implement classification model</li>\n",
    "        <li>Evaluate performnce on test set</li>\n",
    "        <li>Repeat 1 & 2 for all of the classifiers</li>\n",
    "        <li>Select best performing classifier</li>\n",
    "    </ol>\n",
    "    \n",
    "<i> Classifiers from <b>pyspark.ml.classification</b></i>\n",
    "* Logistics Classifier\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Gradient Boost Tree\n",
    "* Naive Bayes\n",
    "* Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_classifier = LogisticRegression(featuresCol = 'feat_vector', labelCol = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_fit = log_reg_classifier.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = log_reg_fit.evaluate(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- feat_vector: vector (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "root\n",
      " |-- feat_vector: vector (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg_predictions.printSchema()\n",
    "predictions.predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|         feat_vector|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|(6,[0,1],[2.0,31.0])|\n",
      "|       0.0|       0|(6,[0,1],[2.0,31.0])|\n",
      "|       0.0|       0|(6,[0,1],[2.0,31.0])|\n",
      "|       0.0|       1|(6,[0,1],[3.0,25.0])|\n",
      "|       1.0|       0|[1.0,2.0,151.55,0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg_predictions.select(['prediction', 'Survived', 'feat_vector']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_evaluator = BinaryClassificationEvaluator(rawPredictionCol = 'rawPrediction', labelCol = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8232952578746979\n"
     ]
    }
   ],
   "source": [
    "bin_eval = bin_evaluator.evaluate(predictions.predictions)\n",
    "print(bin_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Decision Tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"feat_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_fit = dec_tree.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_pred = dec_tree_fit.transform(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79182156133829\n"
     ]
    }
   ],
   "source": [
    "dec_tree_accuracy = evaluator.evaluate(dec_tree_pred)\n",
    "print(dec_tree_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol = 'feat_vector', labelCol = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fit = rf.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_fit.transform(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79182156133829\n"
     ]
    }
   ],
   "source": [
    "rf_accuracy = evaluator.evaluate(rf_pred)\n",
    "print(rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Gradient Boost Tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_classifier = GBTClassifier(featuresCol = 'feat_vector', labelCol = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_classifier_fit = gbt_classifier.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_classifier_pred = gbt_classifier_fit.transform(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7806691449814126\n"
     ]
    }
   ],
   "source": [
    "gbt_classifier_accuracy = evaluator.evaluate(gbt_classifier_pred)\n",
    "print(gbt_classifier_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = NaiveBayes(featuresCol = 'feat_vector', labelCol = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_fit = nb_classifier.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_pred = nb_classifier_fit.transform(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6691449814126395\n"
     ]
    }
   ],
   "source": [
    "nb_classifier_accuracy = evaluator.evaluate(nb_classifier_pred)\n",
    "print(nb_classifier_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Support Vector Machine </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = LinearSVC(featuresCol = 'feat_vector', labelCol = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier_fit = svc_classifier.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier_pred = svc_classifier_fit.transform(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7769516728624535\n"
     ]
    }
   ],
   "source": [
    "svc_classifier_accuracy = evaluator.evaluate(svc_classifier_pred)\n",
    "print(svc_classifier_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Log Reg is performing best </b> <br>\n",
    "<i> Feed test data</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Family_Size: integer (nullable = true)\n",
      " |-- Family_Flag: integer (nullable = false)\n",
      " |-- Sex_dummy: double (nullable = false)\n",
      " |-- Embarked_dummy: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = new_test.columns, outputCol = 'feat_vector')\n",
    "new_test = assembler.transform(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PClass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked_dummy: double (nullable = false)\n",
      " |-- Sex_dummy: double (nullable = false)\n",
      " |-- Family_Flag: integer (nullable = false)\n",
      " |-- feat_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = log_reg_fit.transform(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PClass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked_dummy: double (nullable = false)\n",
      " |-- Sex_dummy: double (nullable = false)\n",
      " |-- Family_Flag: integer (nullable = false)\n",
      " |-- feat_vector: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.withColumn('id', monotonically_increasing_id())\n",
    "test = test.withColumn('id', monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = test.select('id', 'Name').join(other = results.select('id', 'prediction'), on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
